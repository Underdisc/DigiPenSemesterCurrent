Virtual Machine
===============
- A computer and instruction set implemented within another computer
- Can typically run the intermediate representation
- Walks through the byte code and executes each action
- May maintain its own stack and memory
- Can be implemented to be machine independent (especially in C/C++)
- Can be decently fast (Lua)
- Must be careful to respect memory alignment

  - Byte code
  - Stack
  - Arrays
  - Allocations of structures (padding)

Instructions
------------
- Typically ends up being a large enumeration of all the different instructions you support
- Must support encoding and decoding instructions from a stream
- May be variable length, or all fixed sized opcodes
- Instructions may be high-level (allocate object/table, index hash map, etc.)
- Or low level (load/store/move)
- May just directly use your TAC (even in SSA form) for execution

Reduced Instruction Set Computing
---------------------------------
- Also known as **RISC**
- The simplest set of instructions needed to perform all tasks
- Very few instructions with minimal flags
- Typically does not include compound operators such as ``+=``
- Simple to perform optimizations on (few cases to handle)
- Simple to write a virtual machine for
- Results in more lines of code
- Slower for a virtual machine to run because there are more instructions

Consider the following if statement:

.. code-block:: as

  if (x > 5)
  {
    //...
  }

In *RISC* form this may look like:

.. code-block:: as

    t1 = x > 5
    if t1 goto IF_BODY else goto IF_END
  IF_BODY:
    //...
  IF_END:

Consider the following statements:

.. code-block:: as

  ++a;
  b = 0;
  
In *RISC* form this may look like:

.. code-block:: as

  a = a + 1
  b = 0

Complex Instruction Set Computing
---------------------------------
- Also known as **CISC**
- Compound instructions that can perform multiple tasks
- Minimizes the size of the written code
- Complicates the implementation of a virtual machine
- Optimizers now need to account for the many different ways of doing the same thing
- Faster for a virtual machine to run because it can do more in one step
- Especially when each instruction is implemented in a native language (C/C++)

Consider the following if statement:

.. code-block:: as

  if (x > 5)
  {
    //...
  }

.. code-block:: as

    if x > 5 goto IF_BODY else goto IF_END
  IF_BODY:
    //...
  IF_END:


Consider the following statements:

.. code-block:: as

  ++a;
  b = 0;
  
In *CISC* form this may look like:

.. code-block:: as

  inc_and_clear a, b

Stack Machine
-------------
- Every evaluation of an operand pushes a value on the stack
- Every operation pops values from the stack that it requires
- **Not** referring to the stack that we're used to in native applications
- No way to re-use prior computations

The evaluation of the following expression:

.. code-block:: as

  5 + 2

Results in the following expression tree:

.. graphviz::

  digraph
  {
    node [shape=rectangle, fontsize=10, height=0, fontname=Verdana];
    "[Binary]\n+" -> "[Literal]\n5";
    "[Binary]\n+" -> "[Literal]\n2";
  }

In stack machine code it would look like:

::

  push 5
  push 2
  add

- Binary operations pop two arguments from the stack and push one result back on
- Unary operations pop one argument from the stack and push one result back on
  
Looking at a more complicated expression:

.. code-block:: as

  3 + 4 * 9

Results in the following expression tree:

.. graphviz::

  digraph
  {
    node [shape=rectangle, fontsize=10, height=0, fontname=Verdana];
    "[Binary]\n+" -> "[Literal]\n3";
    "[Binary]\n+" -> "[Binary]\n*";
    "[Binary]\n*" -> "[Literal]\n4";
    "[Binary]\n*" -> "[Literal]\n9";
  }

In stack machine code it would look like:

::

  push 3
  push 4
  push 9
  multiply
  add

- In order to generate the stack machine code we write a custom ``Visitor``
- LiteralNode simply pushes its value on the stack
- BinaryNode we visit left, visit right, then emit our operation
- UnaryNode just visits its operand, then emits its operation

Advantages
``````````
- Smaller opcodes since each operation does not need to encode operands
- Simplistic (easy to understand and to generate)
- Efficient usage of stack space

Disadvantages
`````````````
- Stack machines are typically slower

  - Pushing and popping also involves incrementing/decrementing a stack position
  - Less opportunities for optimizations
  - No ability to reuse *already computed* values

- Very few CPUs use stack machine architectures

Random Access Machine
---------------------
- Blocks of contiguous memory where we do all our operations
- Typically an ever expanding **stack**... not to be confused with a *Stack Machine*
- Precomputed locations of operands for each opcode
- May be relative to a stack frame (for a function call)
- May also be referred to as an **infinite register machine**

Advantages
``````````
- Less time spent in pushing and popping operands
- Reuse of any computation left on the stack
- Can compute and reuse locations of *dead* variables / temporaries
- Best *bang for your buck* when implementing a virtual byte-code
- Stack frames can ideally be kept within the cache

Disadvantages
`````````````
- Larger opcode sizes because we must encode locations
- Locations can be anywhere on the stack (how big is an encoded location?)

Register Machine
----------------
- Main memory is typically slow: order(s) of magnitude slower than cache
- Cache levels introduced to speed up memory accesses
- Registers are the fastest memory and are only used for temporary computations
- A fixed number of registers (compiler must determine which and when to use registers)

Advantages
``````````
- Registers are very fast
- Mirrors modern processor architectures

Disadvantages
`````````````
- You can't write a virtual byte-code that takes advantages of registers
- Unless you write inline assembly (machine specific)
- Typically inline assembly disables optimizations by the compiler (MSVC, etc.)
- How do you preserve registers between function calls in your own *Virtual Machine*?

Register Allocation
```````````````````
- Each operation results in a temporary (binary, unary, function call)
- May wish to put local variables in a register (load)
- And then after many computations, copy register back to local variable stack (store)
- Typically a fixed number of registers on hardware
- Registers may be of different types and counts

  - Floating point registers
  - Vector registers (SSE)
  - Integral / pointer registers

Infinite Registers
''''''''''''''''''
- Count the number of temporaries generated after optimization
- Every temporary is assigned a register
- Requires either infinite registers or errors out
- Effectively how Lua works

Consider the following expression:

.. code-block:: as

  (5 + 1) * 2

Consider the following *TAC*:

.. code-block:: as

  1) t1 = 5
  2) t2 = t1 + 1
  3) t3 = t2 * 2

- There were 3 temporaries generated, therefore we use 3 registers

.. code-block:: as

  1) r1 = 5
  2) r2 = r1 + 1
  3) r3 = r2 * 2


.. warning:: Lua considers itself to be a **register machine**. This is because in version 4 they used a stack machine opcode. Version 5 they switched over to explicitly computing argument locations. The "registers" they use are limited up to 255 and are allocated per call frame / function call. Therefore they are ever expanding and effectively infinite. Moreover, these "registers" exist on a stack. Their registers are not representative of hardware registers.

- Quotes from *The Implementation of Lua 5.0*:

  - Since 2003, with the release of Lua 5.0, Lua uses a register-based virtual machine. This register-based machine also uses a stack, for allocating activation records, wherein the registers live. When Lua enters a function, it preallocates from the stack an activation record large enough to hold all the function registers. All local variables are allocated in registers. As a consequence, access to local variables is specially efficient.
  - Registers are kept in the run-time stack, which is essentially an array. Thus, access to registers is fast.

- Lua encodes all of its opcodes within one machine word (32 bit)
- Bit based instructions to decode (cheap)
- Single byte index to refer to a register
- One byte for instruction, 3 bytes for *TAC*
- Lua's registers are effectively its stack, it has no actual stack
- What happens if Lua runs out of registers (too many temporaries or locals?)

  - ``function at line 1 has more than 200 local variables``
  - ``function or expression too complex near '+'``

- Rare case in which code generation can emit compilation errors
  
Register Reuse
''''''''''''''
- We can make better use of registers by analysing the lifetime of a variable/temporary

Consider the following *TAC*:

.. code-block:: as

  1) t1 = 5
  2) t2 = t1 + 1
  3) t3 = t2 * 2

- ``t1`` is only used in lines 1 and 2
- ``t2`` is only used in lines 2 and 3

.. code-block:: as

  1) r1 = 5
  2) r2 = r1 + 1
  3) r1 = r2 * 2

- We were able to reuse ``r1`` on line 3 because the value it last stored was never used again after line 2
- We can do an even better job if we realize that t1 is only ever used on the right hand of line 2

.. code-block:: as

  1) r1 = 5
  2) r1 = r1 + 1
  3) r1 = r1 * 2

.. warning:: Some processors may not allow operations that store the result within the same argument registers

- Rules of register reuse:

  - If two variables are alive at the same point in time, they cannot occupy the same register
  - Conversely, if two variables are alive at different times, they may occupy the same register

- At this phase, we decide when to move values between memory and registers
- No transformations of the IR, only insertions of *load* and *store* opcodes
- In the LLVM IR, the user explicitly does this with *load* and *store*

  - Except the user does not decide registers
  - Load from a pointer to get a value (e.g. int* -> int)
  - Store from a value into a pointer (e.g. int -> int*)
  - All stack allocations are pointers (stack allocating an int results int*)
  - Heavily optimized by their optimization passes
